[
["index.html", "Big Data and Cloud Computing 1 About the course 1.1 Overview 1.2 Registration 1.3 Prerequisites 1.4 Github 1.5 License 1.6 Contact 1.7 Colophon", " Big Data and Cloud Computing Sudhakaran Prabakaran and Matt Wayland 2018-05-30 1 About the course 1.1 Overview Recent advances in genomics, proteomics, imaging and other technologies, have resulted in data being generated at a faster rate than they can be meaningfully analysed. In this course we will show you how cloud computing can be used to meet the challenges of storage, management and analysis of big data. The first half of the course will introduce cloud infrastructure technologies. The second half will cover tools for collaborative working, resource management, and creation of workflows. The instructors will demonstrate how they are using cloud computing in their own research. N.B. If you sign up for this course, you will be automatically registered for an AWS educate account, which will provide you with sufficient AWS credits to complete the course exercises. If you decide to continue using cloud computing after the course, you will need to either purchase more credits or apply for a grant from programs like: AWS Cloud Credits for Research, Microsoft Azure for Research or Google Cloud Platform Education Grants. After this course you should be able to: Launch a virtual machine Build and deploy Docker containers Configure storage Create data analysis workflows Analyse your own data in the cloud During this course you will learn about: Cloud infrastructure technologies Using containers for reproducible research Collaborating in the cloud Managing cloud resources The hierarchy of cloud services: Infrastructure as a Service (IaaS), Platform as a Service (PaaS), Software as a Service (SaaS). 1.2 Registration Bioinformatics Training: Big Data and Cloud Computing 1.3 Prerequisites Familiarity with Linux/Unix would be helpful, but not essential 1.4 Github bioinformatics-training/big-data-cloud 1.5 License GPL-3 1.6 Contact If you have any comments, questions or suggestions about the material, please contact the course instructors: Sudhakaran Prabakaran, and Matt Wayland. 1.7 Colophon This book was produced using the bookdown package (Xie 2017), which was built on top of R Markdown and knitr (Xie 2015). References "],
["rosetta-hub.html", "2 Introduction to RosettaHUB 2.1 Features 2.2 Your account 2.3 Navigating the platform 2.4 AWS", " 2 Introduction to RosettaHUB Rosetta Hub platform as a service 2.1 Features 2.2 Your account 2.3 Navigating the platform 2.4 AWS "],
["containers.html", "3 Images and containers 3.1 Definitions 3.2 Images on RosettaHUB 3.3 Launch a container", " 3 Images and containers 3.1 Definitions Docker images are the basis of containers. An Image is an ordered collection of root filesystem changes and the corresponding execution parameters for use within a container runtime. An image typically contains a union of layered filesystems stacked on top of each other. An image does not have state and it never changes. A container is a runtime instance of a docker image. A Docker container consists of A Docker image An execution environment A standard set of instructions The concept is borrowed from Shipping Containers, which define a standard to ship goods globally. Docker defines a standard to ship software. 3.2 Images on RosettaHUB RosettaHUB provides two types of images: Managed images: These are images that are created and maintained by RosettaHUB or images that are derived from these images. RosettaHUB currently provides two managed images (CPU-Docker RH Workbench and GPU-Nvidia-Docker RH Workbench) which are equipped with a range of tools (Jupyter, Zeppelin, RStudio and RosettaHUB workbench) to facilitate data science and have a user friendly desktop environment. Semi-managed images: These are images that map AMIs on AWS that are not derived from RosettaHUB images. Semi-managed images allow users to easily launch a machine from the RosettaHUB web console using their RosettaHUB keys. Access to the instances is managed by RosettaHUB, ie RosettaHUB generates and saves the private keys associated with the machine and allows you to retrieve any time the credentials to connect your machine using RDP for Windows instances or Ssh for Linux instances. 3.3 Launch a container "],
["storage.html", "4 Storage 4.1 Create an S3 bucket 4.2 Command line", " 4 Storage In this chapter we will show you how to use the Amazon Web Services (AWS) Simple Storage Service (S3) (https://aws.amazon.com/documentation/s3/). 4.1 Create an S3 bucket On S3, objects (data and their metadata) are stored in buckets. RosettaHUB calls these buckets Simple Storage Drives and provides a default bucket for each user. Figure 4.1: Simple storage drive section on Federation console Let’s create a new bucket (simple storage drive) to use on this course. Go to the simple storage drive section on the Federation console and click create. Figure 4.2: Create S3 storage dialog box Specify a Label and Bucket. Accept defaults for all other settings. The Bucket name must be globally unique (https://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html), so here we have combined our username (bioinfo1.cam) with the RosettaHUB domain name: Label: course Bucket: com-rosettahub-course-bioinfo1.cam Figure 4.3: Set Label and Bucket names Once your new simple storage drive has been created, it will be listed alongside your default storage drive. Figure 4.4: New S3 bucket has been added to list of simple storage drives. Left clicking on the new bucket (simple storage drive) will take you to the AWS management console. Try uploading a file. Figure 4.5: S3 bucket web interface. 4.2 Command line 4.2.1 AWS command line tools "],
["customizing-images.html", "5 Customizing images 5.1 Introduction 5.2 Launch machine 5.3 Connect to machine 5.4 Mount S3 storage 5.5 Configure server to send e-mail 5.6 Install R", " 5 Customizing images 5.1 Introduction We can customize any of the managed or semi-managed images provided on RosettaHUB, by installing additional software or making other configuration changes. The process is as follows: launch a RosettaHUB machine install additional software and/or make configuration changes create a new image from the modified machine In Docker terminology, we add a layer to the base image. For some projects we do not want the overhead of a graphical user interface and do not require all of the tools provided by the managed To create a derived managed image, users have to launch a RosettaHUB machine then create an image from that machine on RosettaHUB. Managed images are configured with Docker containers. Docker containers contain applications for data science such as Pyhton, R, Rstudio, Scala, Sql and notebooks such as Jupyter and Zeppelin. We can create derived images from any of these baseline images. Explain example 5.2 Launch machine On Federation Console, go to Images section where you will see the following list: Right click on Ubuntu Server 16.04 LTS and select ‘Launch’ from the context menu. Figure 5.1: Managed images available Figure 5.2: Launch ubuntu server Figure 5.3: Ubuntu server container is listed under formations and sessions 5.3 Connect to machine Figure 5.4: Context menu for ubuntu server container Figure 5.5: Connectivity information for ubuntu server container ls -la private-keys-m-e1f0bf55-815b-439b-afae-a157d59facbe-0.pem -rw-rw-rw-@ 1 matt staff 1674 29 May 20:37 private-keys-m-e1f0bf55-815b-439b-afae-a157d59facbe-0.pem chmod 600 private-keys-m-e1f0bf55-815b-439b-afae-a157d59facbe-0.pem ssh ubuntu@vm-34-245-226-49.rosettavm.com -i private-keys-m-e1f0bf55-815b-439b-afae-a157d59facbe-0.pem 5.4 Mount S3 storage We will use the tool s3fs. Install s3fs from ubuntu repository sudo apt-get install s3fs Find the Access Key ID and Secret Access Key for your default iamuser. They will appear like this: Access Key ID: X Secret Access Key: X Create the /etc/passwd-s3fs file sudo echo ACCESS_KEY_ID:Secret_Access_KEY_ID &gt; /etc/passwd-s3fs Save file, then set appropriate permissions sudo chmod 640 /etc/passwd-s3fs Create a mount point and mount S3 bucket sudo mkdir -p /mnt/s3 sudo s3fs com-rosettahub-default-bioinfo1.cam /mnt/s3 -o passwd_file=/etc/passwd-s3fs unmount sudo umount /mnt/s3 edit /etc/fstab LABEL=cloudimg-rootfs / ext4 defaults,discard 0 0 s3fs#com-rosettahub-default-bioinfo1.cam /mnt/s3 fuse _netdev,allow_other 0 0 5.5 Configure server to send e-mail secure simple mail transfer protocol Update ubuntu repository sudo apt-get update Install the ssmtp package sudo apt-get install ssmtp Setup ssmtp by editing the configuration file sudo nano /etc/ssmtp/ssmtp.conf Adjust and add as necessary to match the following parameters Change “MyEmailAddress” and “MyPassword” to your own. # Config file for sSMTP sendmail # # The person who gets all mail for userids &lt; 1000 # Make this empty to disable rewriting. #root=postmaster root=MyEmailAddress@gmail.com # The place where the mail goes. The actual machine name is required no # MX records are consulted. Commonly mailhosts are named mail.domain.com #mailhub=mail mailhub=smtp.gmail.com:587 AuthUser=MyEmailAddress@gmail.com AuthPass=MyPassword UseTLS=YES UseSTARTTLS=YES # Where will the mail seem to come from? #rewriteDomain= rewriteDomain=gmail.com # The full hostname #hostname=MyMediaServer.home hostname=MyMediaServer.home # Are users allowed to set their own From: address? # YES - Allow the user to specify their own From: address # NO - Use the system generated From: address FromLineOverride=YES Create aliases for local usernames (optional) by editing the /etc/ssmtp/revaliases file sudo nano /etc/ssmtp/revaliases And add into it the desired translation which in our Gmail examples case will be root:username@gmail.com:smtp.gmail.com:587 mainuser:username@gmail.com:smtp.gmail.com:587 From now on, the machine will Email when requested through command line or script. Check setup by creating the a script to send an e-mail to yourself nano send-alert.sh #!/bin/sh MAILFILE=/tmp/email_alert.txt echo &quot;Subject: RosettaHUB job completed!&quot; &gt; $MAILFILE echo &quot;To: mw283@cam.ac.uk&quot; &gt;&gt; $MAILFILE echo &quot;From: from_who@from_where.com&quot; &gt;&gt; $MAILFILE echo &quot;&quot; &gt;&gt; $MAILFILE echo &quot;Test sent on $(date &#39;+%Y/%m/%d at %H:%M:%S&#39;).&quot; &gt;&gt; $MAILFILE echo &quot;&quot; &gt;&gt; $MAILFILE echo &quot;Have a nice day!&quot; &gt;&gt; $MAILFILE cat $MAILFILE | ssmtp mw283@cam.ac.uk rm $MAILFILE Make script executable chmod 700 send-alert.sh Run script ./send-alert.sh 5.6 Install R Check which version of R is available in the ubuntu repository apt-cache policy r-base-core Version 3.2.3 is available, but the latest version of R is 3.5.0. Let’s see if a more recent version of R is available from the official Comprehensive R Archive Network (CRAN) repository. Open /etc/apt/sources.list and add the following line to the end of the file: sudo nano /etc/apt/sources.list deb http://cran.rstudio.com/bin/linux/ubuntu xenial/ Add the key ID for the CRAN network: Ubuntu GPG key: sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E084DAB9 Update the repository: sudo apt update Install the R binaries: sudo apt install r-base R on ubuntu server "],
["formations.html", "6 Formations", " 6 Formations "],
["run-analysis.html", "7 Run data analysis", " 7 Run data analysis "],
["collaboration.html", "8 Collaboration 8.1 Real time collaboration 8.2 Sharing images and formations", " 8 Collaboration 8.1 Real time collaboration 8.2 Sharing images and formations "],
["resources.html", "9 Resources 9.1 Rosetta Hub Documentation 9.2 General Data Protection Regulation (GDPR) 9.3 Docker glossary 9.4 Grants available from service providers", " 9 Resources 9.1 Rosetta Hub Documentation https://docs.rosettahub.com/ 9.2 General Data Protection Regulation (GDPR) 9.2.1 Guidance from the University of Cambridge https://www.information-compliance.admin.cam.ac.uk/data-protection https://www.information-compliance.admin.cam.ac.uk/data-protection/general-data-protection-regulation 9.2.2 AWS GDPR Center https://aws.amazon.com/compliance/gdpr-center/ 9.3 Docker glossary https://docs.docker.com/glossary/ 9.4 Grants available from service providers AWS Cloud Credits for Research Microsoft Azure for Research Google Cloud Platform Education Grants. "],
["references.html", "References", " References "]
]
